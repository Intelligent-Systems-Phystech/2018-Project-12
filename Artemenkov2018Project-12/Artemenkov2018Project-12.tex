\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\bibliographystyle{utf8gost705u}
%\NOREVIEWERNOTES
\title
    [Обучение машинного перевода без параллельных текстов] % Краткое название; не нужно, если полное название влезает в~колонтитул
    {Обучение машинного перевода без параллельных текстов}
\author
    [Артеменков$^1$~А.\,А., Бахтеев$^1$~О.\,Ю., Стрижов$^2$~В.\,В.] % список авторов для колонтитула; не нужен, если основной список влезает в колонтитул
    {Артеменков$^1$~А.\,А., Бахтеев$^1$~О.\,Ю., Стрижов$^2$~В.\,В.} % основной список авторов, выводимый в оглавление
    [Артеменков$^1$~А.\,А., Бахтеев$^1$~О.\,Ю., Стрижов$^2$~В.\,В.] % список авторов, выводимый в заголовок; не нужен, если он не отличается от основного
\thanks
    {Научный руководитель:  Стрижов~В.\,В. 
   Авторы: А.В. Грабовой, О.Ю. Бахтеев, В.В. Стрижов, Eric Gaussier, координатор Малиновский~Г.\,С.
   Консультант:  Бахтеев~О.\,Ю.}
%\email
%    {author@site.ru}
\organization
{$^1$Московский физико-технический институт\par
	$^2$Вычислительный центр им. А.~А. Дородницына ФИЦ ИУ РАН}
\abstract
    {В данной работе исследуется задача машинного перевода между двумя языками. Предлагается подход, основанный на моделях автокодировщиков и не требующий наличия большого корпуса параллельных предложений. Каждому предложению из обоих языков ставится в соответствие вектор в общем скрытом пространстве. Оптимизация проводится таким образом, чтобы скрытые пространства автокодировщиков для разных языков совпадали. Для проверки качества модели проводится вычислительный эксперимент по переводу предложений между парой языков русский-украинский. 

\bigskip
\textbf{Ключевые слова}: \emph {нейронные сети, машинный перевод, автокодировщики}.}
\begin{document}
\maketitle

\section{Введение}

Целью данной работы является решение задачи машинного перевода в отсутствии достаточного корпуса параллельных предложений. При наличии достаточно числа параллельных образцов (порядка нескольких миллионов \cite{bahdanau2014neural}) хорошо себя показывают методы машинного перевода с использованием нейронных сетей (\cite{cho2014properties}, \cite{luong2015effective}). Наилучшие результаты достигаются при использовании глубоких (свёрточных или рекуррентных) нейронных сетей, однако, в данном подходе критично наличие большой обучающей выборки. Частичное решение данной проблемы было найдено в пополнении числа предложений с помощью использования переводчиков более низкого качества. В \cite{bertoldi2009domain} было показано, что данным способом могут быть улучшены результаты работы Moses (\cite{koehn2007moses}). Более общим подходом является отказ от перевода в одну сторону и параллельное обучение переводчиков таким образом, чтобы один пополнял обучающую выборку другого.

Описанный выше метод был использована в \cite{lample2017unsupervised} для перевода предложений с английского языка на французский. В данной работе подобная технология будет применяться для перевода с русского языка на украинский. Рассматриваются автокодировщики, реализованные в виде LSTM (\cite{gers1999learning}, \cite{graves2005framewise}), используемые для прямого и обратного перевода, и сеть-дискриминатор, обучаемая по представлению слова в векторном пространстве (например, \cite{goldberg2014word2vec}) определять язык. Автокодировщики подстраиваются таким образом, чтобы их латентные представления совпадали, или, что эквивалентно, чтобы дискриминатор не мог с достаточной уверенностью определить язык, соответствующий сгенерированному латентному вектору. Для того, чтобы избежать переобучения, добавляется шум, не дающий автокодировщикам переобучиться и начать восстанавливать предложения в точности. Шаг обучения состоит из двух стадий: обучение дискриминатора и обучение переводчика. На первой стадии выбирается случайное предложение из исходного языка, кодируется с добавлением шума (один из вариантов рассмотрен в \cite{kimimproving}) и подаётся на вход дискриминатору. После подстройки его весов аналогичные действия повторяются со случайным предложением из конечного языка. На второй стадии выбирается случайное предложение из исходного языка и переводится текущей версией переводчика на конечный язык. Затем на него накладывается шум, оно кодируется, и считываются показания дискриминатора. После обновления весов предложение переводится обратно в исходный язык и вычисляется значение функции потерь. После шага оптимизации действия повторяются со случайным предложением из конечного языка. Качество полученного в результате переводчика оценивается с помощью метрики BLEU(\cite{papineni2002bleu}).



\bibliography{references}

%\linenumbers

% Решение Программного Комитета:
%\ACCEPTNOTE
%\AMENDNOTE
%\REJECTNOTE
\end{document}
