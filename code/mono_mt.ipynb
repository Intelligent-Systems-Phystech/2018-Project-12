{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mono_mt.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "gj-5_tLcMhdv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Настройка окружения"
      ]
    },
    {
      "metadata": {
        "id": "nxuAPpBzMnDP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Конфигурация\n",
        "\n",
        "На __Google Drive__ должна быть папка, в которую будут записываться все промежуточные результаты (например, разные версии модели). Её имя надо записать в __gdrive_dir__. После первого запуска имеет смысл установить __LOAD_PICKLED = True__, это позволит загрузить переведённый датасет, а не переводить всё заново. Параметр __mode__ отвечает за выбор пары языков (возможные значения: __\"en-fr\"__, __\"ru-uk\"__) "
      ]
    },
    {
      "metadata": {
        "id": "fwrohcwPMpxy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mode = \"en-fr\"\n",
        "#mode = \"ru-uk\" \n",
        "\n",
        "\n",
        "gdrive_dir = 'colab_storage/'\n",
        "LOAD_PICKLED = False\n",
        "\n",
        "# Maximum sentence length\n",
        "max_in_len = 20\n",
        "# Minimum word frequency\n",
        "min_in_freq = 5\n",
        "# Load from saved iteration\n",
        "# -1 for new model\n",
        "LOAD_ITER = -1\n",
        "\n",
        "# Maximum number of iterations to be done\n",
        "niters = 100000\n",
        "# Batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Number of iterations between validations\n",
        "val_per = 500\n",
        "# Batch size for validation (-1 == use full test set)\n",
        "val_size = 500\n",
        "# Number of iterations between printing current iteration\n",
        "it_per = 50\n",
        "# Number of iterations between model saves\n",
        "save_per = 500\n",
        "\n",
        "# Decoder hidden state size\n",
        "decoder_size = 300\n",
        "# Attention net size\n",
        "attn_size = 10\n",
        "# Discriminator size\n",
        "discr_size= 300\n",
        "# Start embeddings optimisation only when loss is sufficiently small \n",
        "border_loss = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q3xgRhtW3cmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Монтируем Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "5_l9L8pBjwhE",
        "colab_type": "code",
        "outputId": "ceb58176-7d69-4b98-ab38-65858e970208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "gdrive = 'gdrive/My\\ Drive/' + gdrive_dir"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "w97gdn8fMR5V",
        "colab_type": "code",
        "outputId": "c46007d1-7885-4fb6-8eec-91f52de526e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade torch nltk"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already up-to-date: nltk in /usr/local/lib/python3.6/dist-packages (3.4)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: singledispatch in /usr/local/lib/python3.6/dist-packages (from nltk) (3.4.0.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4kaEePeOLNHH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Флаг _-nc_ позволяет не скачивать файлы, если они уже есть. "
      ]
    },
    {
      "metadata": {
        "id": "c5-bwtVlLNHM",
        "colab_type": "code",
        "outputId": "250776a0-1e89-419b-ad47-df467eb6c3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "if mode == \"en-fr\":\n",
        "    vec_info = {'en': 'wiki.multi.en.vec',\n",
        "                'fr': 'wiki.multi.fr.vec'}\n",
        "    samples_info = {'en': 'train.lc.norm.tok.en',\n",
        "                    'fr': 'train.lc.norm.tok.fr'}\n",
        "    !wget -nc https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok/train.lc.norm.tok.en\n",
        "    !wget -nc https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok/train.lc.norm.tok.fr\n",
        "    !wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec\n",
        "    !wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.fr.vec\n",
        "\n",
        "elif mode == \"ru-uk\":\n",
        "    vec_info = {'ru': 'wiki.multi.ru.vec',\n",
        "                'uk': 'wiki.multi.uk.vec'}\n",
        "    samples_info = {'ru': 'samples.ru',\n",
        "                    'uk': 'samples.uk'}\n",
        "    !wget -nc https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-12/master/data/opus/samples.ru\n",
        "    !wget -nc https://raw.githubusercontent.com/Intelligent-Systems-Phystech/2018-Project-12/master/data/opus/samples.uk\n",
        "    !wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.ru.vec\n",
        "    !wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.uk.vec"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘train.lc.norm.tok.en’ already there; not retrieving.\n",
            "\n",
            "File ‘train.lc.norm.tok.fr’ already there; not retrieving.\n",
            "\n",
            "File ‘wiki.multi.en.vec’ already there; not retrieving.\n",
            "\n",
            "File ‘wiki.multi.fr.vec’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SAiT9LdLLNHY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Определения\n"
      ]
    },
    {
      "metadata": {
        "id": "Fp_MEHfYLNHc",
        "colab_type": "code",
        "outputId": "a935f735-7595-4106-c75d-d5fce0ef4cae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_SvOu_FLLNHm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Вспомогательные функции"
      ]
    },
    {
      "metadata": {
        "id": "Ndrxt2bdi-vQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu, SmoothingFunction\n",
        "\n",
        "def BLEU(ref_list, hyp_list):\n",
        "  chencherry = SmoothingFunction()\n",
        "  ref_lists = [[r] for r in ref_list]\n",
        "  return corpus_bleu(ref_lists, hyp_list, smoothing_function=chencherry.method1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIUN6jBbLNHo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-ZА-ЯҐЄІЇа-яґєії.!?]+\", r\" \", s)\n",
        "    return s.strip()\n",
        "\n",
        "def read_sentences(path):\n",
        "    lines = []\n",
        "    with open(path) as f:\n",
        "        for line in f:\n",
        "            lines.append(normalizeString(line))\n",
        "    return lines"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GxAYk5IjLNHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def seq_format(seq, max_words):\n",
        "    nwords = len(seq)\n",
        "    seq_new = seq + [\"<EOS>\"]\n",
        "    seq_new += [\"<PAD>\" for i in range(max_words - nwords)]\n",
        "    return seq_new\n",
        "\n",
        "def freq_filter(seq, lang, freq):\n",
        "    if freq == -1:\n",
        "        return True\n",
        "    for w in seq:\n",
        "        if lang.word2count[w] < freq:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def len_filter(seq, max_len):\n",
        "    if max_len == -1:\n",
        "        return True\n",
        "    else:\n",
        "        return len(seq) <= max_len\n",
        "\n",
        "def prepare_list(list, lang, max_words, freq):\n",
        "    list_seq = [s.split() for s in list]\n",
        "    list_clean = []\n",
        "    for s in list_seq:\n",
        "        if len_filter(s, max_words) and freq_filter(s, lang, freq):\n",
        "            list_clean.append(s)\n",
        "        else:\n",
        "            list_clean.append(None)\n",
        "            \n",
        "    return list_clean\n",
        "\n",
        "def seq2ind(seq, lang):\n",
        "    return [lang.word2index[w] for w in seq]\n",
        "\n",
        "def noise(seq, drop_prob=0.1, shuffle_len=3):\n",
        "    n = len(seq)\n",
        "    ind = np.argsort(np.arange(0, n) + np.random.uniform(0, shuffle_len, n))\n",
        "    drop_mask = np.random.binomial(1, 1-drop_prob, n).astype(np.bool)\n",
        "    ind = ind[drop_mask]\n",
        "    res = []\n",
        "    for i in ind:\n",
        "        res.append(seq[i])\n",
        "    return res\n",
        "  \n",
        "def ind2words(ind_seq, vocab):\n",
        "    \"\"\"Translate word indices to words.\n",
        "\n",
        "        Arguments:\n",
        "        ind_seq  -- sequence of indices\n",
        "        lang     -- corresponding vocabulary\n",
        "    \"\"\"\n",
        "    return list(map(lambda x: vocab.index2word[x], ind_seq))\n",
        "\n",
        "def words2sent(words):\n",
        "    \"\"\"Translate word indices to sentence.\n",
        "\n",
        "        Arguments:\n",
        "        words  -- sequence of words\n",
        "        lang     -- corresponding vocabulary\n",
        "    \"\"\"\n",
        "    try:\n",
        "        end = words.index('<EOS>')\n",
        "    except ValueError:\n",
        "        end = len(words)\n",
        "    return ' '.join([w for w in words[:end] if w not in ['<PAD>', '<SOS>', '<EOS>']])\n",
        "\n",
        "def ind2sent(ind_seq, vocab):\n",
        "    return words2sent(ind2words(ind_seq, vocab))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yHrH-PzzLNHz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Словарь\n",
        "\n",
        "Собирает статистику по словам в тексте и умеет выдавать идекс каждого слова."
      ]
    },
    {
      "metadata": {
        "id": "wuFRGD7qQ62O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_vec(emb_path, max_words=-1):\n",
        "    vectors = []\n",
        "    word2id = {}\n",
        "    it = 0\n",
        "    with open(emb_path) as f:\n",
        "        nvec, ndim = [int(k) for k in f.readline().split()]\n",
        "        for line in f:\n",
        "            if max_words != -1 and it > max_words:\n",
        "                break\n",
        "            it += 1\n",
        "            orig_word, vect = line.rstrip().split(' ', 1)\n",
        "            \n",
        "            word = normalizeString(orig_word)\n",
        "            vect = np.fromstring(vect, sep=' ')\n",
        "       \n",
        "            # Words are sorted by frequency, no need to add less \n",
        "            # frequent version of the same word  \n",
        "            if not (word in word2id):\n",
        "                vectors.append(vect)\n",
        "                word2id[word] = len(word2id)\n",
        "\n",
        "    id2word = {v: k for k, v in word2id.items()}\n",
        "    embeddings = np.vstack(vectors)\n",
        "    return embeddings, id2word, word2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AXOlJ9iPLNH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Vocabulary:\n",
        "    \"\"\"\n",
        "    Tracks info about known words, their indices and frequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = []\n",
        "        self.n_words = 0\n",
        "        self.add_seq(self.get_dummies())\n",
        "   \n",
        "    def add_list(self, list):\n",
        "        for s in list:\n",
        "            self.add_sentence(s)\n",
        "    \n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_seq(self, seq):\n",
        "        for word in seq:\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:   \n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word.append(word)\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "        \n",
        "    @staticmethod\n",
        "    def get_dummies():\n",
        "        return [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
        "    \n",
        "    @staticmethod\n",
        "    def get_dummy_ind(w):\n",
        "        return Vocabulary.get_dummies().index(w)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QXpgGTHuLNH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Датасет\n",
        "\n",
        "Хранит данные, отвечает за генерацию перевода, тренировочной и валидационной выборок. "
      ]
    },
    {
      "metadata": {
        "id": "ogfh_r9PLNH_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "class Dataset:\n",
        "    \"\"\"\n",
        "    Data storage and preprocessing.\n",
        "    \"\"\"\n",
        "    def __init__(self, lang_info, max_len=-1, min_freq=-1, val_ratio=0.1):\n",
        "        \"\"\"\n",
        "        Arguments: \n",
        "        lang_info   -- dictionary with following info:\n",
        "                      --> name = language name (str)\n",
        "                      --> corpus_path = path to file with sentences (str)\n",
        "        max_length  -- maximum sentence length (-1 for no limit)\n",
        "        min_freq    -- minimum word appearing frequency (-1 for no limit)\n",
        "        val_ration -- fraction of sentences to use for validation\n",
        "        \"\"\"\n",
        "        self.max_len = max_len\n",
        "        self.min_freq = min_freq\n",
        "        \n",
        "        # Sentences lists\n",
        "        self.s_list = {}\n",
        "        \n",
        "        if len(lang_info) != 2:\n",
        "            raise ValueError('Only pairs of languages are supported, but {} was passed.'.format(len(lang_info)))\n",
        "        self.names = []\n",
        "        for l, path in lang_info.items():\n",
        "            self.names.append(l)\n",
        "            self.s_list[l] = read_sentences(path)\n",
        "            \n",
        "        # Vocabularies \n",
        "        self.v_list = {}\n",
        "        for l in self.names:\n",
        "            self.v_list[l] = Vocabulary(l)\n",
        "            self.v_list[l].add_list(self.s_list[l])\n",
        "    \n",
        "        # Filter sentences\n",
        "        self.seq_list = {} \n",
        "        nsents = []\n",
        "        \n",
        "        seq_list = []\n",
        "        seq_names = []\n",
        "        for l in self.names:\n",
        "            tmp = prepare_list(self.s_list[l], self.v_list[l], \n",
        "                                           max_len, min_freq)\n",
        "            nsents.append(len(tmp))\n",
        "            seq_list.append(tmp)\n",
        "            seq_names.append(l)\n",
        "\n",
        "        if len(set(nsents)) != 1:\n",
        "            raise Warning('Numbers of sentences are not equal for the languages.')\n",
        "        \n",
        "        # Combaine parallel and non-parallel data\n",
        "        nopair = {l:[] for l in seq_names}\n",
        "        pair = {l:[] for l in seq_names}\n",
        "        nfiltered = [0, 0]\n",
        "        npairs = 0\n",
        "        for s in zip(*seq_list):\n",
        "            if s[0] == None and s[1] == None:\n",
        "                continue\n",
        "            if s[1] == None:\n",
        "                nfiltered[0] += 1\n",
        "                nopair[seq_names[0]].append(s[0])\n",
        "            elif s[0] == None:\n",
        "                nfiltered[1] += 1\n",
        "                nopair[seq_names[1]].append(s[1])\n",
        "            else:\n",
        "                nfiltered[0] += 1\n",
        "                nfiltered[1] += 1\n",
        "                npairs += 1\n",
        "                for i in range(2):\n",
        "                    pair[seq_names[i]].append(s[i])\n",
        "       \n",
        "        # Form test and train sentences\n",
        "        wanted_len = int(val_ratio*min(nfiltered))\n",
        "        if wanted_len > npairs:\n",
        "            raise Warning('Asked for {} test samples, but only {} can be provided.'.format(wanted_len, npairs))\n",
        "        res_len = min(npairs, wanted_len)\n",
        "        self.test_list = {}\n",
        "        self.seq_list = {}\n",
        "        self.val_size = res_len\n",
        "        for l in self.names:\n",
        "            self.seq_list[l] = pair[l][res_len:] + nopair[l]\n",
        "            self.test_list[l] = pair[l][:res_len]\n",
        "        # No translated version present\n",
        "        self.seq_tr_list = {}\n",
        "        for l in self.names:\n",
        "            self.seq_tr_list[l] = None\n",
        "        \n",
        "        # No initial embeddings present\n",
        "        self.emb = {}\n",
        "        for l in self.names:\n",
        "            self.emb[l] = None\n",
        "        \n",
        "    def translate(self, translator, info_timeout=30):\n",
        "        \"\"\"Build translation of stored sentences.\n",
        "        \n",
        "            Arguments:\n",
        "            translator   -- an object that has translate_seq(seq, from_lang, to_lang) function,\n",
        "                            where: seq -- sequence of words\n",
        "                                 from_lang, to_lang -- strings\n",
        "            info_timeout -- time between printing info \n",
        "        \"\"\"\n",
        "        other = dict(zip(self.names, self.names[::-1]))\n",
        "        start = time.time()\n",
        "        for l, seq_list in self.seq_list.items():\n",
        "            n = len(seq_list)\n",
        "            self.seq_tr_list[l] = []\n",
        "            for i, s in enumerate(seq_list):\n",
        "                seq_tr = translator.translate_seq(s, l, other[l])\n",
        "                self.seq_tr_list[l].append(seq_tr)\n",
        "                self.v_list[other[l]].add_seq(seq_tr)\n",
        "                if not i % 100:\n",
        "                    end = time.time()\n",
        "                if end - start > info_timeout: \n",
        "                    start = end\n",
        "                    print('[{}] {:.1f}% done'.format(l, i/n*100))\n",
        "                  \n",
        "    def get_train(self, batch_size=1):\n",
        "        \"\"\"Get train data.\n",
        "          \n",
        "          Returns:\n",
        "           X_auto{'en', 'fr'}   --  indexed noisy src sentences\n",
        "           Y_auto{'en', 'fr'}   --  indexed clean src sentences\n",
        "           X_cross{'en', 'fr'}   --  indexed translated noisy src sentences\n",
        "           Y_cross{'en', 'fr'}   --  indexed clean src sentences\n",
        "        \"\"\"\n",
        "        X_auto = {}\n",
        "        Y_auto = {}\n",
        "        \n",
        "        X_cross = {}\n",
        "        Y_cross = {}\n",
        "        other = dict(zip(self.names, self.names[::-1]))\n",
        "        for l, lang in self.v_list.items():\n",
        "            # Autoencoders train\n",
        "            batch_ind = np.random.choice(range(len(self.seq_list[l])), batch_size, replace=False)\n",
        "            seq_list_tmp = [self.seq_list[l][i] for i in batch_ind]\n",
        "            \n",
        "            X_auto_tmp = list(map(noise, seq_list_tmp))\n",
        "            Y_auto_tmp = seq_list_tmp\n",
        "            \n",
        "            # Cross-domain train\n",
        "            batch_ind = np.random.choice(range(len(self.seq_tr_list[l])), batch_size, replace=False)\n",
        "            seq_list_tmp = [self.seq_list[l][i] for i in batch_ind]\n",
        "            seq_tr_list_tmp = [self.seq_tr_list[l][i] for i in batch_ind]\n",
        "            \n",
        "            X_cross_tmp = list(map(noise, seq_tr_list_tmp))\n",
        "            Y_cross_tmp = seq_list_tmp\n",
        "            \n",
        "            vocabs = 3*[self.v_list[l]] + [self.v_list[other[l]]]\n",
        "            seq_lists = [X_auto_tmp, Y_auto_tmp, Y_cross_tmp, X_cross_tmp]\n",
        "            ind_lists = []\n",
        "            for lang, seq_list in zip(vocabs, seq_lists):\n",
        "                max_len = max(list(map(len, seq_list)))\n",
        "                formatted = list(map(lambda x: seq_format(x, max_len), seq_list))\n",
        "                inds = torch.tensor(list(map(lambda x: seq2ind(x, lang), formatted))) \n",
        "                ind_lists.append(inds)\n",
        "                \n",
        "            X_auto[l], Y_auto[l], Y_cross[l], X_cross[l] = ind_lists\n",
        "                \n",
        "        return X_auto, Y_auto, X_cross, Y_cross\n",
        "    \n",
        "    def get_test(self, nsamples=-1):\n",
        "        \"\"\"Get test data.\n",
        "        \n",
        "        Returns:\n",
        "        X{'fr', 'en'} -- pairs of translated sentences \n",
        "        \"\"\"\n",
        "        X = {}\n",
        "        if nsamples==-1:\n",
        "            nsamples = self.val_size\n",
        "        inds = np.random.choice(range(self.val_size), nsamples, replace=False)\n",
        "        for l, lang in self.v_list.items():\n",
        "            test_list_tmp = [self.test_list[l][i] for i in inds]\n",
        "            max_len = max(list(map(len, test_list_tmp)))\n",
        "            formatted = list(map(lambda x: seq_format(x, max_len), test_list_tmp))\n",
        "            X[l] = torch.tensor(list(map(lambda x: seq2ind(x, lang), formatted))) \n",
        "        return X\n",
        "        \n",
        "    def build_initial_embedding(self, lang_info):\n",
        "        \"\"\"\n",
        "        Arguments: \n",
        "        lang_info  -- dictionary with following info:\n",
        "                      --> name = language name (str)\n",
        "                      --> emb_path = path to file with embeddings (str)\n",
        "        \"\"\"   \n",
        "        for l, path in lang_info.items():\n",
        "            embeddings, id2word, word2id = load_vec(path)\n",
        "            cur_voc = self.v_list[l]\n",
        "            \n",
        "            dum_len = len(cur_voc.get_dummies())\n",
        "            emb = torch.zeros((cur_voc.n_words, embeddings.shape[1]+dum_len))\n",
        "            # One-hot for dummies\n",
        "            for i in range(dum_len):\n",
        "              emb[i, -dum_len+i] = 1\n",
        "            # Copy for others\n",
        "            for i in range(dum_len, cur_voc.n_words):\n",
        "              w = cur_voc.index2word[i]\n",
        "              if w in word2id:\n",
        "                emb[i, :-dum_len] = torch.from_numpy(embeddings[word2id[w]])\n",
        "              else:\n",
        "                # To avoid zero\n",
        "                x = torch.rand(embeddings.shape[1]) + 1e-8\n",
        "                emb[i, :-dum_len] = x/x.norm()\n",
        "        \n",
        "            self.emb[l] = emb\n",
        "    def ind2sent(self, ind_seq, lang):\n",
        "        \"\"\"Translate word indices to sentence.\n",
        "        \n",
        "            Arguments:\n",
        "            ind_seq  -- sequence of indices\n",
        "            lang     -- corresponding language ('en', 'fr', ...)\n",
        "        \"\"\"\n",
        "        return ind2sent(ind_seq, self.v_list[lang])\n",
        "      \n",
        "    def ind2words(self, ind_seq, lang):\n",
        "        \"\"\"Translate word indices to words.\n",
        "        \n",
        "            Arguments:\n",
        "            ind_seq  -- sequence of indices\n",
        "            lang     -- corresponding language ('en', 'fr', ...)\n",
        "        \"\"\"\n",
        "        return ind2words(ind_seq, self.v_list[lang])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yjvDcOuqLNII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Переводчик\n",
        "\n",
        "Нулевое приближение перевода, используя натренированные представления слов. Близким словам соответствуют близкие векторы, переводим вектор в вектор."
      ]
    },
    {
      "metadata": {
        "id": "axEcHUWfLNIL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NaiveTranslator:\n",
        "    \"\"\"Naive word-by-word translation with caching.\n",
        "    \"\"\"\n",
        "    def __init__(self, lang_info, max_words=-1):\n",
        "        \"\"\"\n",
        "        Arguments: \n",
        "        lang_info  -- dictionary with following info:\n",
        "                      --> name = language name (str)\n",
        "                      --> emb_path = path to file with embeddings (str)\n",
        "        max_words -- maximum number of embeddings to load (sorted by frequency)\n",
        "        \"\"\"   \n",
        "        self.emb = {}\n",
        "        self.id2word = {}\n",
        "        self.word2id = {}\n",
        "        self.names = []\n",
        "        for l, path in lang_info.items():\n",
        "            self.names.append(l)\n",
        "            self.emb[l], self.id2word[l], self.word2id[l] = load_vec(path, \n",
        "                                                                     max_words)\n",
        "            \n",
        "        self.cache = {l: {} for l in self.names}\n",
        "        # Add dummies\n",
        "        for l in self.names:\n",
        "            for w in [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]:\n",
        "                self.cache[l][w] = w\n",
        "        \n",
        "    def translate(self, word, from_lang, to_lang):\n",
        "        if word in self.cache[from_lang]:\n",
        "            return self.cache[from_lang][word]\n",
        "        else:\n",
        "            # Handle unknown\n",
        "            if word in self.word2id[from_lang]:\n",
        "                id = self.word2id[from_lang][word]\n",
        "            else:\n",
        "                self.cache[from_lang][word] = \"<UNK>\"\n",
        "                return \"<UNK>\"\n",
        "            \n",
        "            vec = self.emb[from_lang][id]\n",
        "            dist = np.dot(self.emb[to_lang], vec)\n",
        "            ind = np.asscalar(np.argmax(dist, axis=0))\n",
        "            tr = self.id2word[to_lang][ind]\n",
        "            self.cache[from_lang][word] = tr    \n",
        "            return tr\n",
        "    \n",
        "    def translate_sent(self, sent, from_lang, to_lang):\n",
        "        new_sent = ' '.join([self.translate(w, from_lang, to_lang) for w in sent.split()])\n",
        "        return new_sent\n",
        "    \n",
        "    def translate_seq(self, seq, from_lang, to_lang):\n",
        "        return [self.translate(w, from_lang, to_lang) for w in seq]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZV1yY4thLNIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Энкодер\n",
        "\n",
        "Обычный GRU. Параметры:\n",
        "* __embeddings__  -- оптимизируемые представления слов\n",
        "* __hidden_size__ -- размерность векторов в скрытом пространстве (предложений), куда отображает энкодер. Совпадает с размерностью вектора состояния RNN (энкодера)  "
      ]
    },
    {
      "metadata": {
        "id": "-MrYuTcaLNIY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, embeddings, hidden_size):\n",
        "        super().__init__()\n",
        "        self.emb = embeddings\n",
        "        self.hidden_size = hidden_size\n",
        "        for emb in embeddings.values():\n",
        "            self.input_size = emb.embedding_dim\n",
        "            \n",
        "        self.gru = nn.GRU(self.input_size, self.hidden_size, batch_first=True,\n",
        "                          bidirectional=True)\n",
        "\n",
        "    def step(self, input, hidden, from_lang):\n",
        "#         print('from', from_lang)\n",
        "#         print('input', input)\n",
        "#         print('hidden', hidden)\n",
        "\n",
        "        embedded = self.emb[from_lang](input)\n",
        "        output, hidden = self.gru(embedded, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "    \n",
        "    def forward(self, ind_batch, nsteps, from_lang):\n",
        "#         print('>>Encoder:step')\n",
        "#         encoder_outputs = torch.zeros((ind_batch.shape[0], nsteps, hidden_size), \n",
        "#                                       device=ind_batch.device)\n",
        "        encoder_hidden = torch.zeros((2, ind_batch.shape[0], self.hidden_size), \n",
        "                                     device=ind_batch.device)\n",
        "# #         print('encoder_outputs', encoder_outputs.shape)\n",
        "#         for i in range(nsteps):\n",
        "# #             print('step:', i)\n",
        "#             encoder_output, encoder_hidden = self.step(ind_batch[:, [i]], encoder_hidden, from_lang)\n",
        "# #             print('encoder_output', encoder_output.shape)\n",
        "#             encoder_outputs[:, i, :] += encoder_output.squeeze()\n",
        "        embedded = self.emb[from_lang](ind_batch)\n",
        "        encoder_outputs, encoder_hidden = self.gru(embedded, encoder_hidden)  \n",
        "#         print('encoder_outputs', encoder_outputs.shape)\n",
        "#         print('encoder_hidden', encoder_hidden.shape)\n",
        "#         print('<<Encoder:step')\n",
        "        \n",
        "        return encoder_outputs, encoder_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSWTZEO3LNId",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Сеть внимания\n",
        "\n",
        "По вектору скрытого пространства и вектору состояния декодера говорит, какое внимание должно быть уделено первому.\n",
        "\n",
        "* __input_size__ -- размер вектора в скрытом пространстве предложений\n",
        "* __state_size__ -- размер вектора скрытого состояния\n",
        "* __inner_size__ -- размер внутреннего слоя"
      ]
    },
    {
      "metadata": {
        "id": "Ipt4OdBJLNIe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Линейный вариант"
      ]
    },
    {
      "metadata": {
        "id": "YsTwcRXGLNIf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnLinear(torch.nn.Module):\n",
        "    def __init__(self, input_size, state_size, inner_size = 10):\n",
        "        super().__init__()\n",
        "        self.W = nn.Linear(input_size + state_size, inner_size)\n",
        "        self.v = nn.Linear(inner_size, 1)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "#         print('>>AttnLinear')\n",
        "#         print('input', input.shape)\n",
        "#         print('hidden', hidden.shape)\n",
        "        expanded = hidden.expand(-1, input.shape[1], -1)\n",
        "#         print('expanded', expanded.shape)\n",
        "#         print('<<AttnLinear')\n",
        "        return torch.relu(self.v(self.W(torch.cat((input, expanded), dim=2))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nT7ydfuULNIl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Вариант в виде сети"
      ]
    },
    {
      "metadata": {
        "id": "BMJ7YD3iLNIn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnNet(torch.nn.Module):\n",
        "    def __init__(self, input_size, state_size, inner_size=10):\n",
        "        super().__init__()\n",
        "        self.v = nn.Linear(inner_size, 1, bias=False)\n",
        "        self.W = nn.Linear(input_size, inner_size, bias=False)\n",
        "        self.U = nn.Linear(state_size, inner_size, bias=False)\n",
        "        \n",
        "    def forward(self, input, hidden):\n",
        "#         print('>>AttnNet')\n",
        "#         print('input', input.shape)\n",
        "#         print('hidden', hidden.shape)\n",
        "#         print('<<AttnNet')\n",
        "        return torch.relu(self.v(self.W(input) + self.U(hidden)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pc4Zk7kaLNIv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Декодер\n",
        "\n",
        "Умеет по представлению предложения в скрытом пространстве (последовательность векторов размерности __hidden_size__) получать последовательность слов для одного из языков.\n",
        "\n",
        "* __embeddings__  -- оптимизируемые представления слов\n",
        "* __hidden_size__ -- размер вектора в скрытом пространстве (предложений)\n",
        "* __state_size__  -- размер вектора состояния RNN (декодера)\n",
        "* __inner_size__  -- размер внутреннего слоя сети внимания "
      ]
    },
    {
      "metadata": {
        "id": "xGqr_7DILNIw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AttnDecoder(torch.nn.Module):\n",
        "    def __init__(self, embeddings, hidden_size, state_size, attn_size):\n",
        "        super().__init__()\n",
        "        self.emb = embeddings\n",
        "        for emb in embeddings.values():\n",
        "            self.emb_size = emb.embedding_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.attn_size = attn_size\n",
        "        self.state_size = state_size\n",
        "\n",
        "        self.attn = AttnLinear(hidden_size, state_size, attn_size)\n",
        "        self.gru = nn.GRU(hidden_size + self.emb_size, state_size, batch_first=True)\n",
        "        self.out = nn.ModuleDict()\n",
        "        for l, emb in embeddings.items():\n",
        "            self.out[l] = nn.Linear(state_size, emb.num_embeddings)\n",
        "        \n",
        "    def step(self, ind, hidden, encoder_outputs, to_lang):\n",
        "#         print('hidden', hidden.shape)\n",
        "        input = self.emb[to_lang](ind)\n",
        "#         print('encoder_outputs', encoder_outputs.shape)\n",
        "        attn_weights = torch.softmax(\n",
        "            self.attn(encoder_outputs, hidden.transpose(0, 1)), dim=1)\n",
        "#         print('attn_weights', attn_weights.shape)\n",
        "        attn_applied = torch.bmm(attn_weights.transpose(1, 2), encoder_outputs)\n",
        "#         print('attn_applied', attn_applied.shape)\n",
        "        gru_input = torch.cat((input, attn_applied), dim=2)\n",
        "#         print('gru_input', gru_input.shape)\n",
        "        output, hidden = self.gru(gru_input, hidden)\n",
        "        output = self.out[to_lang](output)\n",
        "        output = torch.log_softmax(output, dim=2)\n",
        "        \n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def forward(self, encoder_outputs, nsteps, to_lang):\n",
        "#         print('>>AttnDecoder')\n",
        "        decoder_outputs = torch.zeros((encoder_outputs.shape[0], nsteps,\n",
        "                                       self.emb[to_lang].num_embeddings), \n",
        "                                       device=encoder_outputs.device)\n",
        "#         print('decoder_outputs', decoder_outputs.shape)\n",
        "        # Load encoded hidden state\n",
        "#         decoder_hidden = encoder_outputs[:, -1, :].unsqueeze(0).contiguous()\n",
        "\n",
        "        decoder_hidden = torch.zeros((1, encoder_outputs.shape[0], self.state_size), \n",
        "                                     device=encoder_outputs.device)\n",
        "        # Get SOS (start of sentence)\n",
        "        input = torch.full((encoder_outputs.shape[0], 1),\n",
        "                           Vocabulary.get_dummy_ind('<SOS>'),\n",
        "                           dtype=torch.long)\n",
        "        input = input.to(encoder_outputs.device)\n",
        "        for i in range(nsteps):\n",
        "#             print('step', i)\n",
        "            decoder_output, decoder_hidden, attn_weights = self.step(input, \n",
        "                                                       decoder_hidden, \n",
        "                                                       encoder_outputs,\n",
        "                                                       to_lang)\n",
        "#             print('decoder_output', decoder_output.shape)\n",
        "            decoder_outputs[:, [i], :] += decoder_output\n",
        "            _, input = decoder_output.topk(1, dim=2)\n",
        "#             print('input', input.shape)\n",
        "            input = input.view(encoder_outputs.shape[0], 1)\n",
        "        \n",
        "#         print('<<AttnDecoder')\n",
        "        return decoder_outputs, decoder_hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HBXiq9QxLNI1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Дискриминатор\n",
        "\n",
        "Умеет по представлению предложения в скрытом пространстве (последовательность векторов размерности __hidden_size__) говорить, какому из двух языков (__0__ или __1__) она принадлежит.\n",
        "\n",
        "* __hidden_size__ -- размер вектора в скрытом пространстве (предложений)\n",
        "* __hidden_len__  -- максимальная длина последовательности векторов в скрытом пространстве; она же максимальная длина входный предложений\n",
        "* __hidden_layer_size__  -- размер скрытого слоя"
      ]
    },
    {
      "metadata": {
        "id": "qhVOswe3LNI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, hidden_size, hidden_layer_size, smooth_coef=1e-1):\n",
        "        super().__init__()\n",
        "        self.smooth_coef = smooth_coef\n",
        "        self.hidden_size = hidden_size\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.hid = nn.Linear(hidden_size, hidden_layer_size)\n",
        "        self.hid2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
        "        self.out = nn.Linear(hidden_layer_size, 1)\n",
        "        \n",
        "    def forward(self, input):\n",
        "#         print('>>Discriminator')\n",
        "        input = torch.relu(input)\n",
        "        out = torch.relu(self.hid(input))\n",
        "        out = torch.sigmoid(self.out(torch.relu(self.hid2(out)))).squeeze()\n",
        "      \n",
        "        # Add smoothing\n",
        "        smooth = torch.eye(out.shape[-1], device=input.device)*self.smooth_coef\n",
        "        smooth[0, 0] = 1\n",
        "        for i in range(1, out.shape[-1]):\n",
        "          smooth[:i, i] = (1-self.smooth_coef)*smooth[:i, i-1]\n",
        "#         print('<<Discriminator')\n",
        "        return torch.mm(out, smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B2K_1iL9LNI-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Обёртка\n",
        "\n",
        "Управляет всеми частями модели. Параметры соответствуют описанным выше."
      ]
    },
    {
      "metadata": {
        "id": "7OuJz3TvLNI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Wrapper(nn.Module):\n",
        "    def __init__(self, decoder_size, attn_size, discr_size, dataset):\n",
        "        super().__init__()\n",
        "        self.emb = nn.ModuleDict()\n",
        "        self.names = []\n",
        "        for name, emb in dataset.emb.items():\n",
        "            self.emb[name] = nn.Embedding.from_pretrained(emb, freeze=False)\n",
        "            self.names.append(name)\n",
        "            self.hidden_size = self.emb[name].embedding_dim\n",
        "        self.decoder_size = decoder_size\n",
        "        self.attn_size = attn_size\n",
        "        self.discr_size = discr_size\n",
        "        \n",
        "        #Bidirectional encoder\n",
        "        self.enc = Encoder(self.emb, self.hidden_size)\n",
        "        self.dec = AttnDecoder(self.emb, 2*self.hidden_size, decoder_size, attn_size)\n",
        "        self.discr = Discriminator(2*self.hidden_size, discr_size)\n",
        "        \n",
        "    def encode(self, ind_batch, from_lang):\n",
        "        return self.enc(ind_batch, ind_batch.shape[1], from_lang)\n",
        "    \n",
        "    def decode(self, encoder_outputs, output_len, to_lang):\n",
        "        return self.dec(encoder_outputs, output_len, to_lang)\n",
        "    \n",
        "    def encode_decode(self, ind_batch, from_lang, to_lang, out_len=None):\n",
        "        if out_len == None:\n",
        "            out_len = ind_batch.shape[1]\n",
        "        \n",
        "        encoder_outputs, encoder_hidden = self.encode(ind_batch, from_lang)\n",
        "        decoder_outputs, decoder_hidden = self.decode(encoder_outputs, out_len, to_lang)\n",
        "        \n",
        "        return encoder_outputs, decoder_outputs\n",
        "    \n",
        "    def discriminate(self, encoder_outputs):\n",
        "        return self.discr(encoder_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QZmIwM7yjers",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Translator:\n",
        "    def __init__(self, wrapper, vocabs, max_len):\n",
        "        self.wrapper = wrapper\n",
        "        self.vocabs = vocabs\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def translate_seq(self, seq, from_lang, to_lang):\n",
        "        ind_seq = seq2ind(seq, self.vocabs[from_lang]) +\\\n",
        "                              [self.vocabs[from_lang].get_dummy_ind('<EOS>')]\n",
        "        device = self.wrapper.enc.gru.weight_hh_l0.device\n",
        "        ind_seq = torch.LongTensor(ind_seq).unsqueeze(0).to(device)\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs, decoder_outputs =\\\n",
        "                           self.wrapper.encode_decode(ind_seq, from_lang, \n",
        "                                                      to_lang, self.max_len)\n",
        "        _, ind = decoder_outputs.squeeze().topk(1, dim=1)\n",
        "        return ind2words(ind.squeeze().cpu().tolist(), self.vocabs[to_lang])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k7MUAZ6ZskT4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class IndTranslator:\n",
        "    def __init__(self, wrapper, max_len):\n",
        "        self.wrapper = wrapper\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def translate(self, ind_batch, from_lang, to_lang):\n",
        "        device = self.wrapper.enc.gru.weight_hh_l0.device\n",
        "        with torch.no_grad():\n",
        "            encoder_outputs, decoder_outputs =\\\n",
        "                           self.wrapper.encode_decode(ind_batch, from_lang, \n",
        "                                                      to_lang, self.max_len)\n",
        "        _, ind = decoder_outputs.squeeze().topk(1, dim=1)\n",
        "        return ind.squeeze()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SCyFaOvnLNJF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Загрузка датасета\n",
        "\n",
        "Если был указан параметр __LOAD_PICKLED = True__, то загружается из файла. Иначе создаётся заново: процесс не очень быстрый."
      ]
    },
    {
      "metadata": {
        "id": "ZLsXCdlYLNJH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if LOAD_PICKLED:\n",
        "    !cp $gdrive\"\"NaiveTranslator ./\n",
        "    with open('NaiveTranslator', 'rb') as f:\n",
        "        tr = pickle.load(f)\n",
        "else:\n",
        "    tr = NaiveTranslator(vec_info)\n",
        "    with open('NaiveTranslator', 'wb') as f:\n",
        "        pickle.dump(tr, f)\n",
        "        \n",
        "    !cp NaiveTranslator $gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tHvt10BeLNJN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if LOAD_PICKLED:\n",
        "    !cp $gdrive\"\"Dataset ./\n",
        "    with open('Dataset', 'rb') as f:\n",
        "        D = pickle.load(f)\n",
        "else:\n",
        "    print('-> Loading dataset')\n",
        "    D = Dataset(samples_info, max_in_len, min_in_freq)\n",
        "    print('-> Translating')\n",
        "    D.translate(tr)\n",
        "    print('-> Building embedding')\n",
        "    D.build_initial_embedding(vec_info)\n",
        "   \n",
        "    with open('Dataset', 'wb') as f:\n",
        "        pickle.dump(D, f)\n",
        "        \n",
        "    !cp Dataset $gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DGgI1oQULNJU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Пример генерации обучающей/тестовой выборки."
      ]
    },
    {
      "metadata": {
        "id": "bqk2n83MLNJY",
        "colab_type": "code",
        "outputId": "e4bf8cea-3ab4-4fef-dd69-1fa04b454a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "train = D.get_train(1)\n",
        "\n",
        "ls = mode.split(\"-\")\n",
        "for l in ls:\n",
        "  print('{} train samples: {}'.format(l, len(D.seq_list[l])))\n",
        "  print('{} test samples: {}'.format(l, len(D.test_list[l])))\n",
        "  \n",
        "print('\\nExamples:')\n",
        "l, other = ls\n",
        "\n",
        "print('X_auto:', D.ind2sent(train[0][l][0], l))\n",
        "print('Y_auto:', D.ind2sent(train[1][l][0], l))\n",
        "print('X_cross:', D.ind2sent(train[2][l][0], other))\n",
        "print('Y_cross:', D.ind2sent(train[3][l][0], l))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en train samples: 18209\n",
            "en test samples: 1832\n",
            "fr train samples: 16493\n",
            "fr test samples: 1832\n",
            "\n",
            "Examples:\n",
            "X_auto: am wearing older person a blue sitting on jacket a bench eating cream ice . cone\n",
            "Y_auto: am older person wearing a blue jacket sitting on a bench eating an ice cream cone .\n",
            "X_cross: deux hommes dans une sont bureaux wrestling deux comme autres regarder hommes .\n",
            "Y_cross: two men in an office are wrestling as two other men watch on .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-VSzVMZ7LNJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Тренировка модели"
      ]
    },
    {
      "metadata": {
        "id": "HjmLrgU-hPil",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if LOAD_ITER != -1:\n",
        "    param = gdrive+f'checkpoint.{LOAD_ITER}' + ' ./'\n",
        "    !cp $param"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "K3r8fO7vLNJo",
        "colab_type": "code",
        "outputId": "19380b64-658d-449a-c642-549b0b80d4f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "cell_type": "code",
      "source": [
        "# Ability to translate\n",
        "tr_crit = nn.NLLLoss()\n",
        "# Ability to fool the discriminator\n",
        "tr_fake_crit = nn.BCELoss()\n",
        "# Ability to predict language correctly\n",
        "discr_crit = nn.BCELoss()\n",
        "\n",
        "wr = Wrapper(decoder_size, attn_size, discr_size, D).to(device)\n",
        "\n",
        "if LOAD_ITER != -1:\n",
        "    checkpoint = torch.load(f'checkpoint.{LOAD_ITER}')\n",
        "    wr.load_state_dict(checkpoint['state_dict'])\n",
        "else:\n",
        "    LOAD_ITER = 0\n",
        "\n",
        "# Discriminator optimizer\n",
        "d_opt = torch.optim.RMSprop(wr.discr.parameters(), lr=0.0005)\n",
        "# Encoder and decoder optimizer\n",
        "tr_opt = torch.optim.Adam(list(wr.enc.parameters()) + list(wr.dec.parameters()),\n",
        "                          lr=0.0003, betas=(0.5, 0.999))\n",
        "\n",
        "# Assign classes to languages\n",
        "class_num = {name:cl for cl, name in enumerate(D.names)}\n",
        "# Dict with lang pairs\n",
        "other = dict(zip(D.names, D.names[::-1]))\n",
        "# Get index of PAD \n",
        "pad_ind = Vocabulary.get_dummy_ind('<PAD>')\n",
        "\n",
        "start = time.time()\n",
        "avg_d_loss = 0\n",
        "avg_tr_loss = 0\n",
        "\n",
        "\n",
        "# Don't touch embeddings at the beginning \n",
        "for name in D.names:\n",
        "  wr.emb[name].weight.requires_grad = False\n",
        "\n",
        "for it in range(LOAD_ITER, LOAD_ITER + niters):\n",
        "    # Refresh gradients\n",
        "    tr_opt.zero_grad()\n",
        "    d_opt.zero_grad()\n",
        "    \n",
        "    # Get training batch\n",
        "    X_auto, Y_auto, X_cross, Y_cross = D.get_train(batch_size)\n",
        "    \n",
        "    # Losses to be accumulated\n",
        "    d_loss = 0\n",
        "    tr_loss = 0\n",
        "    # Train autoencoders\n",
        "    for l in D.names:\n",
        "        # Noisy sentences \n",
        "        X_auto[l] = X_auto[l].to(device)\n",
        "        # Clean sentences\n",
        "        Y_auto[l] = Y_auto[l].to(device)\n",
        "        # Noisy translation to other language \n",
        "        X_cross[l] = X_cross[l].to(device)\n",
        "        # Source sentences \n",
        "        Y_cross[l] = Y_cross[l].to(device)\n",
        "\n",
        "        ## AUTOENCODER PHASE\n",
        "        \n",
        "        encoder_outputs, decoder_outputs =\\\n",
        "                           wr.encode_decode(X_auto[l], \n",
        "                                            l,\n",
        "                                            l,\n",
        "                                            Y_auto[l].shape[1])\n",
        "        \n",
        "        # Dont penalize padding\n",
        "        if torch.any(Y_auto[l] == pad_ind):\n",
        "            decoder_outputs[Y_auto[l] == pad_ind][:, pad_ind] = 0\n",
        "        tr_loss += tr_crit(decoder_outputs.transpose(1, 2), Y_auto[l])\n",
        "        # We want to predict wrong class labels (fool the discriminator)\n",
        "        predicted = wr.discriminate(encoder_outputs)\n",
        "        wanted = torch.full_like(predicted, class_num[other[l]], device=device)\n",
        "        tr_loss += tr_fake_crit(predicted, wanted)\n",
        "        \n",
        "        # And predict correct classes by discriminator\n",
        "        # .detach() allows us to ignore subgraph, \n",
        "        # connected with encoder+decoder\n",
        "        correct = torch.full_like(predicted, class_num[l], device=device)\n",
        "        predicted_det = wr.discriminate(encoder_outputs.detach())\n",
        "        d_loss += discr_crit(predicted_det, correct)\n",
        "        \n",
        "        ## CROSS-DOMAIN PHASE\n",
        "        ## Repeats previous phase with the only difference of source\n",
        "        ## language change\n",
        "        \n",
        "        encoder_outputs, decoder_outputs =\\\n",
        "                       wr.encode_decode(X_cross[l], \n",
        "                                        other[l], # language changed here\n",
        "                                        l,\n",
        "                                        Y_cross[l].shape[1])\n",
        "        if torch.any(Y_cross[l] == pad_ind):\n",
        "            decoder_outputs[Y_cross[l] == pad_ind][:, pad_ind] = 0\n",
        "        tr_loss += tr_crit(decoder_outputs.transpose(1, 2), Y_cross[l])\n",
        "        \n",
        "        # Language is changed here too\n",
        "        predicted = wr.discriminate(encoder_outputs)\n",
        "        wanted = torch.full_like(predicted, class_num[l], device=device)\n",
        "        tr_loss += tr_fake_crit(predicted, wanted)\n",
        "        \n",
        "        correct = torch.full_like(predicted, class_num[other[l]], device=device)\n",
        "        predicted_det = wr.discriminate(encoder_outputs.detach())\n",
        "        d_loss += discr_crit(predicted_det, correct)\n",
        "        \n",
        "    ## STATISTICS\n",
        "    \n",
        "    avg_d_loss += d_loss.item()\n",
        "    avg_tr_loss += tr_loss.item()\n",
        "    \n",
        "    ## BACKPROPAGATION PHASE\n",
        "    \n",
        "    # Activate embedding training only when loss is low enough\n",
        "    for name in D.names:\n",
        "        if tr_loss.item() < border_loss:\n",
        "            wr.emb[name].weight.requires_grad = True\n",
        "        else:\n",
        "            wr.emb[name].weight.requires_grad = False\n",
        "        \n",
        "    ## OPTIMISATION STEP\n",
        "    \n",
        "    # We don't want Discriminator weights to be affected\n",
        "    for p in wr.discr.parameters():\n",
        "        p.requires_grad = False\n",
        "    # Computed encoder and decoder gradients\n",
        "    tr_loss.backward()\n",
        "    # Undo the changes\n",
        "    for p in wr.discr.parameters():\n",
        "        p.requires_grad = True\n",
        "    tr_opt.step()\n",
        "    \n",
        "    # Now calculate the Discriminator loss\n",
        "    d_loss.backward()\n",
        "    d_opt.step()\n",
        "\n",
        "    if not it % it_per and it != LOAD_ITER:\n",
        "        end = time.time()\n",
        "        print('Iterations: {} ({} sec/iter)'.format(it, (end-start)/it_per))\n",
        "        print('Average losses:')\n",
        "        print('\\td_loss:', avg_d_loss/it_per)\n",
        "        print('\\ttr_loss:', avg_tr_loss/it_per)\n",
        "        avg_tr_loss = 0\n",
        "        avg_d_loss = 0\n",
        "        start = time.time()\n",
        "        \n",
        "    if not it % save_per and it != LOAD_ITER:\n",
        "        path = f'checkpoint.{it}'\n",
        "        torch.save({'state_dict': wr.state_dict()}, path)\n",
        "        print('Saved model to:', path)\n",
        "        param = f'checkpoint.{it}' + ' ' + gdrive\n",
        "        !cp $param\n",
        "        \n",
        "    if not it % val_per and it != LOAD_ITER:\n",
        "        print('Last loss:')\n",
        "        print('  d_loss =', d_loss.data)\n",
        "        print('  tr_loss =', tr_loss.data)\n",
        "        print(f'\\n[{it}] Validation:')\n",
        "        \n",
        "        wr_tr = IndTranslator(wr, max_in_len)\n",
        "        X = D.get_test(val_size)\n",
        "        ref_list = []\n",
        "        hyp_list = []\n",
        "        print('Sample translations:')\n",
        "        for l in D.names:\n",
        "            print('\\t', other[l], ' --> ', l)\n",
        "            \n",
        "            # Save reference sentences\n",
        "            ind_list = X[l].cpu().tolist()\n",
        "            sent_list = [D.ind2sent(inds, l) for inds in ind_list]    \n",
        "            print('\\t<< ', D.ind2sent(X[other[l]][0].cpu().tolist(), other[l]))\n",
        "            print('\\t== ', sent_list[0])\n",
        "            ref_list += sent_list\n",
        "            \n",
        "            # Translate them\n",
        "            X_cur = X[other[l]].to(device)\n",
        "            X_tr = wr_tr.translate(X_cur, other[l], l)\n",
        "\n",
        "            # Save translations\n",
        "            ind_list = X_tr.cpu().tolist()\n",
        "            sent_list = [D.ind2sent(inds, l) for inds in ind_list]\n",
        "            print('\\t>> ', sent_list[0])\n",
        "            hyp_list += sent_list\n",
        "        \n",
        "        print('BLEU: {:.2f}\\n'.format(BLEU(ref_list, hyp_list)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iterations: 50 (0.8806374597549439 sec/iter)\n",
            "Average losses:\n",
            "\td_loss: 2.832704029083252\n",
            "\ttr_loss: 25.757073135375975\n",
            "Iterations: 100 (0.8620437860488892 sec/iter)\n",
            "Average losses:\n",
            "\td_loss: 2.773097095489502\n",
            "\ttr_loss: 18.760179443359377\n",
            "Iterations: 150 (0.8616536855697632 sec/iter)\n",
            "Average losses:\n",
            "\td_loss: 2.772863893508911\n",
            "\ttr_loss: 18.164194564819336\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
