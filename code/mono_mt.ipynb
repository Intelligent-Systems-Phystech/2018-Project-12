{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных\n",
    "\n",
    "Флаг _-nc_ позволяет не скачивать файлы, если они уже есть. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ‘train.lc.norm.tok.fr’ already there; not retrieving.\n",
      "\n",
      "File ‘train.lc.norm.tok.en’ already there; not retrieving.\n",
      "\n",
      "File ‘wiki.multi.en.vec’ already there; not retrieving.\n",
      "\n",
      "File ‘wiki.multi.fr.vec’ already there; not retrieving.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok/train.lc.norm.tok.fr\n",
    "!wget -nc https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok/train.lc.norm.tok.en\n",
    "!wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.en.vec\n",
    "!wget -nc https://s3.amazonaws.com/arrival/embeddings/wiki.multi.fr.vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определения\n",
    "\n",
    "После первого запуска имеет смысл установить __LOAD_PICKLED = True__, это позволит загрузить переведённый датасет, а не переводить всё заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "LOAD_PICKLED = False\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вспомогательные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "def read_sentences(path):\n",
    "    lines = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            lines.append(normalizeString(line))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_format(seq, max_words):\n",
    "    nwords = len(seq)\n",
    "    seq_new = seq + [\"<EOS>\"]\n",
    "    seq_new += [\"<PAD>\" for i in range(max_words - nwords)]\n",
    "    return seq_new\n",
    "\n",
    "def freq_filter(seq, lang, freq):\n",
    "    if freq == -1:\n",
    "        return True\n",
    "    for w in seq:\n",
    "        if lang.word2count[w] < freq:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def len_filter(seq, max_len):\n",
    "    if max_len == -1:\n",
    "        return True\n",
    "    else:\n",
    "        return len(seq) <= max_len\n",
    "\n",
    "def prepare_list(list, lang, max_words, freq):\n",
    "    list_seq = [s.split() for s in list]\n",
    "    list_clean = []\n",
    "    for s in list_seq:\n",
    "        if len_filter(s, max_words) and freq_filter(s, lang, freq):\n",
    "            list_clean.append(s)\n",
    "        else:\n",
    "            list_clean.append(None)\n",
    "            \n",
    "    return list_clean\n",
    "\n",
    "def seq2ind(seq, lang):\n",
    "    return [lang.word2index[w] for w in seq]\n",
    "\n",
    "def noise(seq, drop_prob=0.1, shuffle_len=3):\n",
    "    n = len(seq)\n",
    "    ind = np.argsort(np.arange(0, n) + np.random.uniform(0, shuffle_len, n))\n",
    "    drop_mask = np.random.binomial(1, 1-drop_prob, n).astype(np.bool)\n",
    "    ind = ind[drop_mask]\n",
    "    res = []\n",
    "    for i in ind:\n",
    "        res.append(seq[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Словарь\n",
    "\n",
    "Собирает статистику по словам в тексте и умеет выдавать идекс каждого слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    Tracks info about known words, their indices and frequences.\n",
    "    \"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.dummies = self.get_dummies()\n",
    "        for i, name in enumerate(self.dummies):\n",
    "            self.word2index[name] = i\n",
    "            self.word2count[name] = 0\n",
    "        self.index2word = self.dummies.copy()\n",
    "        self.n_words = len(self.dummies)\n",
    "   \n",
    "    def add_list(self, list):\n",
    "        for s in list:\n",
    "            self.add_sentence(s)\n",
    "    \n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_seq(self, seq):\n",
    "        for word in seq:\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:   \n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word.append(word)\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dummies():\n",
    "        return [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_dummy_ind(w):\n",
    "        return Vocabulary.get_dummies().index(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Датасет\n",
    "\n",
    "Хранит данные, отвечает за генерацию перевода, тренировочной и валидационной выборок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Data storage and preprocessing.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang_info, max_len=-1, min_freq=-1, val_ratio=0.1):\n",
    "        \"\"\"\n",
    "        Arguments: \n",
    "        lang_info   -- dictionary with following info:\n",
    "                      --> name = language name (str)\n",
    "                      --> corpus_path = path to file with sentences (str)\n",
    "        max_length  -- maximum sentence length (-1 for no limit)\n",
    "        min_freq    -- minimum word appearing frequency (-1 for no limit)\n",
    "        val_ration -- fraction of sentences to use for validation\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.min_freq = min_freq\n",
    "        \n",
    "        # Sentences lists\n",
    "        self.s_list = {}\n",
    "        \n",
    "        if len(lang_info) != 2:\n",
    "            raise ValueError('Only pairs of languages are supported, but {} was passed.'.format(len(lang_info)))\n",
    "        self.names = []\n",
    "        for l, path in lang_info.items():\n",
    "            self.names.append(l)\n",
    "            self.s_list[l] = read_sentences(path)\n",
    "            \n",
    "        # Vocabularies \n",
    "        self.v_list = {}\n",
    "        for l in self.names:\n",
    "            self.v_list[l] = Vocabulary(l)\n",
    "            self.v_list[l].add_list(self.s_list[l])\n",
    "    \n",
    "        # Filter sentences\n",
    "        self.seq_list = {} \n",
    "        nsents = []\n",
    "        \n",
    "        seq_list = []\n",
    "        seq_names = []\n",
    "        for l in self.names:\n",
    "            tmp = prepare_list(self.s_list[l], self.v_list[l], \n",
    "                                           max_len, min_freq)\n",
    "            nsents.append(len(tmp))\n",
    "            seq_list.append(tmp)\n",
    "            seq_names.append(l)\n",
    "\n",
    "        if len(set(nsents)) != 1:\n",
    "            raise Warning('Numbers of sentences are not equal for the languages.')\n",
    "        \n",
    "        # Combaine parallel and non-parallel data\n",
    "        nopair = {l:[] for l in seq_names}\n",
    "        pair = {l:[] for l in seq_names}\n",
    "        nfiltered = [0, 0]\n",
    "        npairs = 0\n",
    "        for s in zip(*seq_list):\n",
    "            if s[0] == None and s[1] == None:\n",
    "                continue\n",
    "            if s[1] == None:\n",
    "                nfiltered[0] += 1\n",
    "                nopair[seq_names[0]].append(s[0])\n",
    "            elif s[0] == None:\n",
    "                nfiltered[1] += 1\n",
    "                nopair[seq_names[1]].append(s[1])\n",
    "            else:\n",
    "                nfiltered[0] += 1\n",
    "                nfiltered[1] += 1\n",
    "                npairs += 1\n",
    "                for i in range(2):\n",
    "                    pair[seq_names[i]].append(s[i])\n",
    "       \n",
    "        # Form test and train sentences\n",
    "        wanted_len = int(val_ratio*min(nfiltered))\n",
    "        if wanted_len > npairs:\n",
    "            raise Warning('Asked for {} test samples, but only {} can be provided.'.format(wanted_len, npairs))\n",
    "        res_len = min(npairs, wanted_len)\n",
    "        self.test_list = {}\n",
    "        self.seq_list = {}\n",
    "        self.val_size = res_len\n",
    "        for l in self.names:\n",
    "            self.seq_list[l] = pair[l][res_len:] + nopair[l]\n",
    "            self.test_list[l] = pair[l][:res_len]\n",
    "        # No translated version present\n",
    "        self.seq_tr_list = {}\n",
    "        for l in self.names:\n",
    "            self.seq_tr_list[l] = None\n",
    "        \n",
    "    def translate(self, translator):\n",
    "        \"\"\"Build translation of stored sentences.\n",
    "        \n",
    "            Arguments:\n",
    "            translator -- an object that has translate_seq(seq, from_lang, to_lang) function,\n",
    "                          where: seq -- sequence of words\n",
    "                                 from_lang, to_lang -- strings\n",
    "        \"\"\"\n",
    "        other = dict(zip(self.names, self.names[::-1]))\n",
    "        for l, seq_list in self.seq_list.items():\n",
    "            self.seq_tr_list[l] = [translator.translate_seq(s, l, other[l]) for s in seq_list]\n",
    "            for seq in self.seq_tr_list[l]:\n",
    "                self.v_list[other[l]].add_seq(seq)\n",
    "            \n",
    "    def get_train(self, batch_size=1):\n",
    "        \"\"\"Get train data.\n",
    "          \n",
    "          Returns:\n",
    "           X_auto{'en', 'fr'}   --  indexed noisy src sentences\n",
    "           Y_auto{'en', 'fr'}   --  indexed clean src sentences\n",
    "           X_cross{'en', 'fr'}   --  indexed translated noisy src sentences\n",
    "           Y_cross{'en', 'fr'}   --  indexed clean src sentences\n",
    "        \"\"\"\n",
    "        X_auto = {}\n",
    "        Y_auto = {}\n",
    "        \n",
    "        X_cross = {}\n",
    "        Y_cross = {}\n",
    "        other = dict(zip(self.names, self.names[::-1]))\n",
    "        for l, lang in self.v_list.items():\n",
    "            # Autoencoders train\n",
    "            batch_ind = np.random.choice(range(len(self.seq_list[l])), batch_size, replace=False)\n",
    "            seq_list_tmp = [self.seq_list[l][i] for i in batch_ind]\n",
    "            \n",
    "            X_auto_tmp = list(map(noise, seq_list_tmp))\n",
    "            Y_auto_tmp = seq_list_tmp\n",
    "            \n",
    "            # Cross-domain train\n",
    "            batch_ind = np.random.choice(range(len(self.seq_tr_list[l])), batch_size, replace=False)\n",
    "            seq_list_tmp = [self.seq_list[l][i] for i in batch_ind]\n",
    "            seq_tr_list_tmp = [self.seq_tr_list[l][i] for i in batch_ind]\n",
    "            \n",
    "            X_cross_tmp = list(map(noise, seq_tr_list_tmp))\n",
    "            Y_cross_tmp = seq_list_tmp\n",
    "            \n",
    "            vocabs = 3*[self.v_list[l]] + [self.v_list[other[l]]]\n",
    "            seq_lists = [X_auto_tmp, Y_auto_tmp, Y_cross_tmp, X_cross_tmp]\n",
    "            ind_lists = []\n",
    "            for lang, seq_list in zip(vocabs, seq_lists):\n",
    "                max_len = max(list(map(len, seq_list)))\n",
    "                formatted = list(map(lambda x: seq_format(x, max_len), seq_list))\n",
    "                inds = torch.tensor(list(map(lambda x: seq2ind(x, lang), formatted))) \n",
    "                ind_lists.append(inds)\n",
    "                \n",
    "            X_auto[l], Y_auto[l], Y_cross[l], X_cross[l] = ind_lists\n",
    "                \n",
    "        return X_auto, Y_auto, X_cross, Y_cross\n",
    "    \n",
    "    def get_test(self, nsamples=-1):\n",
    "        \"\"\"Get test data.\n",
    "        \n",
    "        Returns:\n",
    "        X{'fr', 'en'} -- pairs of translated sentences \n",
    "        \"\"\"\n",
    "        X = {}\n",
    "        if nsamples==-1:\n",
    "            nsamples = self.val_size\n",
    "        inds = np.random.choice(range(self.val_size), nsamples, replace=False)\n",
    "        for l, lang in self.v_list.items():\n",
    "            test_list_tmp = [self.test_list[l][i] for i in inds]\n",
    "            max_len = max(list(map(len, test_list_tmp)))\n",
    "            formatted = list(map(lambda x: seq_format(x, max_len), test_list_tmp))\n",
    "            X[l] = torch.tensor(list(map(lambda x: seq2ind(x, lang), formatted))) \n",
    "        return X\n",
    "    \n",
    "    def ind2sent(self, ind_seq, lang):\n",
    "        \"\"\"Translate word indices to words.\n",
    "        \n",
    "            Arguments:\n",
    "            ind_seq  -- sequence of indices\n",
    "            lang     -- corresponding language ('en', 'fr', ...)\n",
    "        \"\"\"\n",
    "        words = list(map(lambda x: self.v_list[lang].index2word[x], ind_seq))\n",
    "        try:\n",
    "            end = words.index('<EOS>')\n",
    "        except ValueError:\n",
    "            end = len(ind_seq)\n",
    "        return ' '.join(words[:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Переводчик\n",
    "\n",
    "Нулевое приближение перевода, используя натренированные представления слов. Близким словам соответствуют близкие векторы, переводим вектор в вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_vec(emb_path, max_words=-1):\n",
    "    vectors = []\n",
    "    word2id = {}\n",
    "    it = 0\n",
    "    with open(emb_path) as f:\n",
    "        nvec, ndim = [int(k) for k in f.readline().split()]\n",
    "        for line in f:\n",
    "            if max_words != -1 and it > max_words:\n",
    "                break\n",
    "            it += 1\n",
    "            orig_word, vect = line.rstrip().split(' ', 1)\n",
    "            \n",
    "            word = normalizeString(orig_word)\n",
    "            vect = np.fromstring(vect, sep=' ')\n",
    "       \n",
    "            # Words are sorted by frequency, no need to add less \n",
    "            # frequent version of the same word  \n",
    "            if not (word in word2id):\n",
    "                vectors.append(vect)\n",
    "                word2id[word] = len(word2id)\n",
    "\n",
    "    id2word = {v: k for k, v in word2id.items()}\n",
    "    embeddings = np.vstack(vectors)\n",
    "    return embeddings, id2word, word2id\n",
    "\n",
    "class NaiveTranslator:\n",
    "    \"\"\"Naive word-by-word translation with caching.\n",
    "    \"\"\"\n",
    "    def __init__(self, lang_info, max_words=-1):\n",
    "        \"\"\"\n",
    "        Arguments: \n",
    "        lang_info  -- dictionary with following info:\n",
    "                      --> name = language name (str)\n",
    "                      --> emb_path = path to file with embeddings (str)\n",
    "        max_words -- maximum number of embeddings to load (sorted by frequency)\n",
    "        \"\"\"   \n",
    "        self.emb = {}\n",
    "        self.id2word = {}\n",
    "        self.word2id = {}\n",
    "        self.names = []\n",
    "        for l, path in lang_info.items():\n",
    "            self.names.append(l)\n",
    "            self.emb[l], self.id2word[l], self.word2id[l] = load_vec(path, \n",
    "                                                                     max_words)\n",
    "            \n",
    "        self.cache = {l: {} for l in self.names}\n",
    "        # Add dummies\n",
    "        for l in self.names:\n",
    "            for w in [\"<SOS>\", \"<EOS>\", \"<PAD>\", \"<UNK>\"]:\n",
    "                self.cache[l][w] = w\n",
    "        \n",
    "    def translate(self, word, from_lang, to_lang):\n",
    "        if word in self.cache[from_lang]:\n",
    "            return self.cache[from_lang][word]\n",
    "        else:\n",
    "            # Handle unknown\n",
    "            if word in self.word2id[from_lang]:\n",
    "                id = self.word2id[from_lang][word]\n",
    "            else:\n",
    "                self.cache[from_lang][word] = \"<UNK>\"\n",
    "                return \"<UNK>\"\n",
    "            \n",
    "            vec = self.emb[from_lang][id]\n",
    "            dist = np.dot(self.emb[to_lang], vec)\n",
    "            ind = np.asscalar(np.argmax(dist, axis=0))\n",
    "            tr = self.id2word[to_lang][ind]\n",
    "            self.cache[from_lang][word] = tr    \n",
    "            return tr\n",
    "    \n",
    "    def translate_sent(self, sent, from_lang, to_lang):\n",
    "        new_sent = ' '.join([self.translate(w, from_lang, to_lang) for w in sent.split()])\n",
    "        return new_sent\n",
    "    \n",
    "    def translate_seq(self, seq, from_lang, to_lang):\n",
    "        return [self.translate(w, from_lang, to_lang) for w in seq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Энкодер\n",
    "\n",
    "Обычный GRU. Параметры:\n",
    "* __embeddings__  -- оптимизируемые представления слов\n",
    "* __hidden_size__ -- размерность векторов в скрытом пространстве (предложений), куда отображает энкодер. Совпадает с размерностью вектора состояния RNN (энкодера)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, embeddings, hidden_size):\n",
    "        super().__init__()\n",
    "        self.emb = embeddings\n",
    "        self.hidden_size = hidden_size\n",
    "        for emb in embeddings.values():\n",
    "            self.input_size = emb.embedding_dim\n",
    "            \n",
    "        self.gru = nn.GRU(self.input_size, self.hidden_size, batch_first=True)\n",
    "\n",
    "    def step(self, input, hidden, from_lang):\n",
    "#         print('from', from_lang)\n",
    "#         print('input', input)\n",
    "#         print('hidden', hidden)\n",
    "\n",
    "        embedded = self.emb[from_lang](input)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "\n",
    "        return output, hidden\n",
    "    \n",
    "    def forward(self, ind_batch, nsteps, from_lang):\n",
    "#         print('>>Encoder:step')\n",
    "        encoder_outputs = torch.zeros((ind_batch.shape[0], nsteps, hidden_size), \n",
    "                                      device=ind_batch.device)\n",
    "        encoder_hidden = torch.zeros((1, ind_batch.shape[0], hidden_size), \n",
    "                                     device=ind_batch.device)\n",
    "#         print('encoder_outputs', encoder_outputs.shape)\n",
    "        for i in range(nsteps):\n",
    "#             print('step:', i)\n",
    "            encoder_output, encoder_hidden = self.step(ind_batch[:, [i]], encoder_hidden, from_lang)\n",
    "#             print('encoder_output', encoder_output.shape)\n",
    "            encoder_outputs[:, i, :] += encoder_output.squeeze()\n",
    "#         print('<<Encoder:step')\n",
    "        \n",
    "        return encoder_outputs, encoder_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сеть внимания\n",
    "\n",
    "По вектору скрытого пространства и вектору состояния декодера говорит, какое внимание должно быть уделено первому.\n",
    "\n",
    "* __input_size__ -- размер вектора в скрытом пространстве предложений\n",
    "* __state_size__ -- размер вектора скрытого состояния\n",
    "* __inner_size__ -- размер внутреннего слоя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Линейный вариант"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnLinear(torch.nn.Module):\n",
    "    def __init__(self, input_size, state_size, inner_size = 10):\n",
    "        super().__init__()\n",
    "        self.W = nn.Linear(input_size + state_size, inner_size)\n",
    "        self.v = nn.Linear(inner_size, 1)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "#         print('>>AttnLinear')\n",
    "#         print('input', input.shape)\n",
    "#         print('hidden', hidden.shape)\n",
    "#         print('<<AttnLinear')\n",
    "        expanded = hidden.expand(-1, input.shape[1], -1)\n",
    "        return torch.relu(self.v(self.W(torch.cat((input, expanded), dim=2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вариант в виде сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, state_size, inner_size=10):\n",
    "        super().__init__()\n",
    "        self.v = nn.Linear(inner_size, 1, bias=False)\n",
    "        self.W = nn.Linear(input_size, inner_size, bias=False)\n",
    "        self.U = nn.Linear(state_size, inner_size, bias=False)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "#         print('>>AttnNet')\n",
    "#         print('input', input.shape)\n",
    "#         print('hidden', hidden.shape)\n",
    "#         print('<<AttnNet')\n",
    "        return torch.relu(self.v(self.W(input) + self.U(hidden)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Декодер\n",
    "\n",
    "Умеет по представлению предложения в скрытом пространстве (последовательность векторов размерности __hidden_size__) получать последовательность слов для одного из языков.\n",
    "\n",
    "* __embeddings__  -- оптимизируемые представления слов\n",
    "* __hidden_size__ -- размер вектора в скрытом пространстве (предложений)\n",
    "* __state_size__  -- размер вектора состояния RNN (декодера)\n",
    "* __inner_size__  -- размер внутреннего слоя сети внимания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttnDecoder(torch.nn.Module):\n",
    "    def __init__(self, embeddings, hidden_size, state_size, attn_size):\n",
    "        super().__init__()\n",
    "        self.emb = embeddings\n",
    "        for emb in embeddings.values():\n",
    "            self.emb_size = emb.embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn_size = attn_size\n",
    "        self.state_size = state_size\n",
    "\n",
    "        self.attn = AttnLinear(hidden_size, state_size, attn_size)\n",
    "        self.gru = nn.GRU(hidden_size + self.emb_size, state_size, batch_first=True)\n",
    "        self.out = nn.ModuleDict()\n",
    "        for l, emb in embeddings.items():\n",
    "            self.out[l] = nn.Linear(state_size, emb.num_embeddings)\n",
    "        \n",
    "    def step(self, ind, hidden, encoder_outputs, to_lang):\n",
    "#         print('>>AttnDecoder')\n",
    "#         print('hidden', hidden.shape)\n",
    "        input = self.emb[to_lang](ind)\n",
    "        attn_weights = torch.softmax(\n",
    "            self.attn(encoder_outputs, hidden.transpose(0, 1)), dim=1)\n",
    "#         print('attn_weights', attn_weights.shape)\n",
    "        attn_applied = torch.bmm(attn_weights.transpose(1, 2), encoder_outputs)\n",
    "#         print('encoder_outputs', encoder_outputs.shape)\n",
    "#         print('attn_applied', attn_applied.shape)\n",
    "        gru_input = torch.cat((input, attn_applied), dim=2)\n",
    "#         print('gru_input', gru_input.shape)\n",
    "        output, hidden = self.gru(torch.cat((input, attn_applied), dim=2), hidden)\n",
    "        output = self.out[to_lang](attn_applied)\n",
    "        output = torch.log_softmax(output, dim=2)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def forward(self, encoder_outputs, nsteps, to_lang):\n",
    "#         print('>>AttnDecoder')\n",
    "        decoder_outputs = torch.zeros((encoder_outputs.shape[0], nsteps,\n",
    "                                       self.emb[to_lang].num_embeddings), \n",
    "                                       device=encoder_outputs.device)\n",
    "#         print('decoder_outputs', decoder_outputs.shape)\n",
    "        # Load encoded hidden state\n",
    "        decoder_hidden = encoder_outputs[:, -1, :].unsqueeze(0).contiguous()\n",
    "        # Get SOS (start of sentence)\n",
    "        input = torch.full((encoder_outputs.shape[0], 1),\n",
    "                           Vocabulary.get_dummy_ind('<SOS>'),\n",
    "                           dtype=torch.long)\n",
    "        input = input.to(encoder_outputs.device)\n",
    "        for i in range(nsteps):\n",
    "#             print('step', i)\n",
    "            decoder_output, decoder_hidden, attn_weights = self.step(input, \n",
    "                                                       decoder_hidden, \n",
    "                                                       encoder_outputs,\n",
    "                                                       to_lang)\n",
    "#             print('decoder_output', decoder_output.shape)\n",
    "            decoder_outputs[:, [i], :] += decoder_output\n",
    "            _, input = decoder_output.topk(1, dim=2)\n",
    "#             print('input', input.shape)\n",
    "            input = input.view(encoder_outputs.shape[0], 1)\n",
    "        \n",
    "#         print('<<AttnDecoder')\n",
    "        return decoder_outputs, decoder_hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дискриминатор\n",
    "\n",
    "Умеет по представлению предложения в скрытом пространстве (последовательность векторов размерности __hidden_size__) говорить, какому из двух языков (__0__ или __1__) она принадлежит.\n",
    "\n",
    "* __hidden_size__ -- размер вектора в скрытом пространстве (предложений)\n",
    "* __hidden_len__  -- максимальная длина последовательности векторов в скрытом пространстве; она же максимальная длина входный предложений\n",
    "* __hidden_layer_size__  -- размер скрытого слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, hidden_size, hidden_len, hidden_layer_size):\n",
    "        super().__init__()\n",
    "        self.hidden_len = hidden_len\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.mesh = nn.Linear(hidden_len, 1)\n",
    "        self.hid = nn.Linear(hidden_size, hidden_layer_size)\n",
    "        self.out = nn.Linear(hidden_layer_size, 1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "#         print('>>Discriminator')\n",
    "        device = input.device\n",
    "        pad = self.hidden_len - input.shape[1]\n",
    "#         print('pad', pad)\n",
    "        padding = torch.zeros((input.shape[0], pad, input.shape[2]), device=device) \n",
    "#         print('input', input.shape)\n",
    "        input = torch.cat((input, padding), dim=1)\n",
    "        input = torch.relu(self.mesh(input.transpose(1, 2)))\n",
    "#         print('<<Discriminator')\n",
    "        return torch.sigmoid(self.out(torch.relu(self.hid(input.transpose(1, 2)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обёртка\n",
    "\n",
    "Управляет всеми частями модели. Параметры соответствуют описанным выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, hidden_size, decoder_size, attn_size, discr_size, max_in_len, dataset):\n",
    "        super().__init__()\n",
    "        self.emb = nn.ModuleDict()\n",
    "        self.names = []\n",
    "        for name, vocab in dataset.v_list.items():\n",
    "            self.emb[name] = nn.Embedding(len(vocab.word2index), hidden_size)\n",
    "            self.names.append(name)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.decoder_size = decoder_size\n",
    "        self.attn_size = attn_size\n",
    "        self.discr_size = discr_size\n",
    "        self.max_in_len = max_in_len\n",
    "        \n",
    "        self.enc = Encoder(self.emb, hidden_size)\n",
    "        self.dec = AttnDecoder(self.emb, hidden_size, decoder_size, attn_size)\n",
    "        self.discr = Discriminator(hidden_size, max_in_len, discr_size)\n",
    "        \n",
    "    def encode(self, ind_batch, from_lang):\n",
    "        return self.enc(ind_batch, ind_batch.shape[1], from_lang)\n",
    "    \n",
    "    def decode(self, encoder_outputs, output_len, to_lang):\n",
    "        return self.dec(encoder_outputs, output_len, to_lang)\n",
    "    \n",
    "    def encode_decode(self, ind_batch, from_lang, to_lang, out_len=None):\n",
    "        if out_len == None:\n",
    "            out_len = ind_batch.shape[1]\n",
    "        \n",
    "        encoder_outputs, encoder_hidden = self.encode(ind_batch, from_lang)\n",
    "        decoder_outputs, decoder_hidden = self.decode(encoder_outputs, out_len, to_lang)\n",
    "        \n",
    "        return encoder_outputs, decoder_outputs\n",
    "    \n",
    "    def discriminate(self, encoder_outputs):\n",
    "        return self.discr(encoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка датасета\n",
    "\n",
    "Если был указан параметр __LOAD_PICKLED = True__, то загружается из файла. Иначе создаётся заново: процесс не очень быстрый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_PICKLED:\n",
    "    with open('NaiveTranslator', 'rb') as f:\n",
    "        tr = pickle.load(f)\n",
    "else:\n",
    "    lang_info = {'fr': 'wiki.multi.fr.vec',\n",
    "                 'en': 'wiki.multi.en.vec'}\n",
    "\n",
    "    tr = NaiveTranslator(lang_info)\n",
    "    with open('NaiveTranslator', 'wb') as f:\n",
    "        pickle.dump(tr, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_in_len = 10\n",
    "min_in_freq = 5\n",
    "\n",
    "if LOAD_PICKLED:\n",
    "    with open('Dataset', 'rb') as f:\n",
    "        D = pickle.load(f)\n",
    "else:\n",
    "    lang_info = {'fr': 'train.lc.norm.tok.fr',\n",
    "                 'en': 'train.lc.norm.tok.en'}\n",
    "\n",
    "    D = Dataset(lang_info, max_in_len, min_in_freq)\n",
    "    D.translate(tr)\n",
    "    with open('Dataset', 'wb') as f:\n",
    "        pickle.dump(D, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример генерации обучающей/тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_auto: une femme tenant un jaune la sous pluie .\n",
      "Y_auto: une femme tenant un parapluie jaune sous la pluie .\n",
      "X_cross: dogs leaping four by above a . obstacle\n",
      "Y_cross: quatre chiens sautant par dessus un obstacle .\n"
     ]
    }
   ],
   "source": [
    "train = D.get_train(50)\n",
    "l = 'fr'\n",
    "other = 'en'\n",
    "print('X_auto:', D.ind2sent(train[0][l][0], l))\n",
    "print('Y_auto:', D.ind2sent(train[1][l][0], l))\n",
    "print('X_cross:', D.ind2sent(train[2][l][0], other))\n",
    "print('Y_cross:', D.ind2sent(train[3][l][0], l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тренировка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 0\n",
      "Saved model to: checkpoint.0\n",
      "Last loss:\n",
      "  d_loss = tensor(2.7549, device='cuda:0')\n",
      "  tr_loss = tensor(40.1062, device='cuda:0')\n",
      "[0] Validation:\n",
      "\n",
      " fr  -->  en\n",
      "<<  une statue argentee d apos hommes sur des velos .\n",
      "==  a silver statue of men on bikes .\n",
      ">>  chelsea chelsea chelsea chelsea chelsea chelsea chelsea chelsea chelsea\n",
      "\n",
      " en  -->  fr\n",
      "<<  a silver statue of men on bikes .\n",
      "==  une statue argentee d apos hommes sur des velos .\n",
      ">>  danseur danseur danseur danseur danseur danseur danseur danseur danseur danseur danseur\n",
      "Iterations: 10\n",
      "Iterations: 20\n",
      "Iterations: 30\n",
      "Iterations: 40\n",
      "Iterations: 50\n",
      "Iterations: 60\n",
      "Iterations: 70\n",
      "Iterations: 80\n",
      "Iterations: 90\n",
      "Iterations: 100\n",
      "Saved model to: checkpoint.100\n",
      "Last loss:\n",
      "  d_loss = tensor(2.9585, device='cuda:0')\n",
      "  tr_loss = tensor(34.4259, device='cuda:0')\n",
      "[100] Validation:\n",
      "\n",
      " fr  -->  en\n",
      "<<  le chien chasse la chevre dans la cour .\n",
      "==  the dog is chasing the goat around the yard .\n",
      ">>  a a a a a a a a a a a\n",
      "\n",
      " en  -->  fr\n",
      "<<  the dog is chasing the goat around the yard .\n",
      "==  le chien chasse la chevre dans la cour .\n",
      ">>  plage plage plage plage plage plage plage plage plage plage\n",
      "Iterations: 110\n",
      "Iterations: 120\n",
      "Iterations: 130\n",
      "Iterations: 140\n",
      "Iterations: 150\n",
      "Iterations: 160\n",
      "Iterations: 170\n",
      "Iterations: 180\n",
      "Iterations: 190\n",
      "Iterations: 200\n",
      "Saved model to: checkpoint.200\n",
      "Last loss:\n",
      "  d_loss = tensor(2.7812, device='cuda:0')\n",
      "  tr_loss = tensor(26.7634, device='cuda:0')\n",
      "[200] Validation:\n",
      "\n",
      " fr  -->  en\n",
      "<<  un jeune homme tenant une enorme tronconneuse .\n",
      "==  a young man holding a huge chainsaw .\n",
      ">>  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      " en  -->  fr\n",
      "<<  a young man holding a huge chainsaw .\n",
      "==  un jeune homme tenant une enorme tronconneuse .\n",
      ">>  sur sur sur sur sur sur sur sur sur\n",
      "Iterations: 210\n",
      "Iterations: 220\n",
      "Iterations: 230\n",
      "Iterations: 240\n",
      "Iterations: 250\n",
      "Iterations: 260\n",
      "Iterations: 270\n",
      "Iterations: 280\n",
      "Iterations: 290\n",
      "Iterations: 300\n",
      "Saved model to: checkpoint.300\n",
      "Last loss:\n",
      "  d_loss = tensor(2.7569, device='cuda:0')\n",
      "  tr_loss = tensor(24.1434, device='cuda:0')\n",
      "[300] Validation:\n",
      "\n",
      " fr  -->  en\n",
      "<<  une foule se rassemble pour ecouter un orchestre\n",
      "==  crowd gathers to listen to a band\n",
      ">>  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
      "\n",
      " en  -->  fr\n",
      "<<  crowd gathers to listen to a band\n",
      "==  une foule se rassemble pour ecouter un orchestre\n",
      ">>  une une une une une une une une une\n",
      "Iterations: 310\n",
      "Iterations: 320\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-e4bebbd9fd00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;31m# Computed encoder and decoder gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;31m# Undo the changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load from saved iteration\n",
    "# -1 for new model\n",
    "LOAD_ITER = -1\n",
    "\n",
    "batch_size = 50\n",
    "niters = 1000\n",
    "# Number of iterations between validations\n",
    "val_per = 100\n",
    "# Number of iterations between printing current iteration\n",
    "it_per = 10\n",
    "# Number of iterations between model saves\n",
    "save_per = 100\n",
    "\n",
    "# Ability to translate\n",
    "tr_crit = nn.NLLLoss()\n",
    "# Ability to fool the discriminator\n",
    "tr_fake_crit = nn.BCELoss()\n",
    "# Ability to predict language correctly\n",
    "discr_crit = nn.BCELoss()\n",
    "\n",
    "hidden_size = 10\n",
    "decoder_size = 10\n",
    "attn_size = 5\n",
    "discr_size= 300 \n",
    "# Add one position for <EOS> symbol\n",
    "max_len = max_in_len + 1\n",
    "\n",
    "wr = Wrapper(hidden_size, decoder_size, attn_size, discr_size, max_len, D).to(device)\n",
    "\n",
    "if LOAD_ITER != -1:\n",
    "    checkpoint = torch.load(f'checkpoint.{LOAD_ITER}')\n",
    "    wr.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "# Discriminator optimizer\n",
    "d_opt = torch.optim.Adam(wr.discr.parameters())\n",
    "# Encoder and decoder optimizer\n",
    "tr_opt = torch.optim.Adam(list(wr.enc.parameters()) + list(wr.dec.parameters()))\n",
    "\n",
    "# Assign classes to languages\n",
    "class_num = {name:cl for cl, name in enumerate(D.names)}\n",
    "# Dict with lang pairs\n",
    "other = dict(zip(D.names, D.names[::-1]))\n",
    "# Get index of PAD \n",
    "pad_ind = Vocabulary.get_dummy_ind('<PAD>')\n",
    "\n",
    "for it in range(niters):\n",
    "    # Refresh gradients\n",
    "    tr_opt.zero_grad()\n",
    "    d_opt.zero_grad()\n",
    "    \n",
    "    # Get training batch\n",
    "    X_auto, Y_auto, X_cross, Y_cross = D.get_train(batch_size)\n",
    "    \n",
    "    # Losses to be accumulated\n",
    "    d_loss = 0\n",
    "    tr_loss = 0\n",
    "    # Train autoencoders\n",
    "    for l in D.names:\n",
    "        # Noisy sentences \n",
    "        X_auto[l] = X_auto[l].to(device)\n",
    "        # Clean sentences\n",
    "        Y_auto[l] = Y_auto[l].to(device)\n",
    "        # Noisy translation to other language \n",
    "        X_cross[l] = X_cross[l].to(device)\n",
    "        # Source sentences \n",
    "        Y_cross[l] = Y_cross[l].to(device)\n",
    "\n",
    "        ## AUTOENCODER PHASE\n",
    "        \n",
    "        encoder_outputs, decoder_outputs =\\\n",
    "                           wr.encode_decode(X_auto[l], \n",
    "                                            l,\n",
    "                                            l,\n",
    "                                            Y_auto[l].shape[1])\n",
    "        \n",
    "        # Dont penalize padding\n",
    "        if torch.any(Y_auto[l] == pad_ind):\n",
    "            decoder_outputs[Y_auto[l] == pad_ind][:, pad_ind] = 0\n",
    "        tr_loss += tr_crit(decoder_outputs.transpose(1, 2), Y_auto[l])\n",
    "        # We want to predict wrong class labels (fool the discriminator)\n",
    "        predicted = wr.discriminate(encoder_outputs)\n",
    "        wanted = torch.full_like(predicted, class_num[other[l]], device=device)\n",
    "        tr_loss += tr_fake_crit(predicted, wanted)\n",
    "        \n",
    "        # And predict correct classes by discriminator\n",
    "        # .detach() allows us to ignore subgraph, \n",
    "        # connected with encoder+decoder\n",
    "        correct = torch.full_like(predicted, class_num[l], device=device)\n",
    "        predicted_det = wr.discriminate(encoder_outputs.detach())\n",
    "        d_loss += discr_crit(predicted_det, correct)\n",
    "        \n",
    "        ## CROSS-DOMAIN PHASE\n",
    "        ## Repeats previous phase with the only difference of source\n",
    "        ## language change\n",
    "        \n",
    "        encoder_outputs, decoder_outputs =\\\n",
    "                       wr.encode_decode(X_cross[l], \n",
    "                                        other[l], # language changed here\n",
    "                                        l,\n",
    "                                        Y_cross[l].shape[1])\n",
    "        if torch.any(Y_cross[l] == pad_ind):\n",
    "            decoder_outputs[Y_cross[l] == pad_ind][:, pad_ind] = 0\n",
    "        tr_loss += tr_crit(decoder_outputs.transpose(1, 2), Y_cross[l])\n",
    "        \n",
    "        # Language is changed here too\n",
    "        predicted = wr.discriminate(encoder_outputs)\n",
    "        wanted = torch.full_like(predicted, class_num[l], device=device)\n",
    "        tr_loss += tr_fake_crit(predicted, wanted)\n",
    "        \n",
    "        correct = torch.full_like(predicted, class_num[other[l]], device=device)\n",
    "        predicted_det = wr.discriminate(encoder_outputs.detach())\n",
    "        d_loss += discr_crit(predicted_det, correct)\n",
    "        \n",
    "    ## BACKPROPAGATION PHASE\n",
    "    \n",
    "    # We don't want Discriminator weights to be affected\n",
    "    for p in wr.discr.parameters():\n",
    "        p.requires_grad = False\n",
    "    # Computed encoder and decoder gradients\n",
    "    tr_loss.backward()\n",
    "    # Undo the changes\n",
    "    for p in wr.discr.parameters():\n",
    "            p.requires_grad = True\n",
    "    \n",
    "    # Now calculate the Discriminator loss\n",
    "    d_loss.backward()\n",
    "    \n",
    "    ## OPTIMISATION STEP\n",
    "    d_opt.step()\n",
    "    tr_opt.step()\n",
    "\n",
    "    if not it % it_per:\n",
    "        print('Iterations:', it)\n",
    "        \n",
    "    if not it % save_per:\n",
    "        path = f'checkpoint.{it}'\n",
    "        torch.save({'state_dict': wr.state_dict()}, path)\n",
    "        print('Saved model to:', path)\n",
    "        \n",
    "    if not it % val_per: \n",
    "        print('Last loss:')\n",
    "        print('  d_loss =', d_loss.data)\n",
    "        print('  tr_loss =', tr_loss.data)\n",
    "        X = D.get_test(1)\n",
    "        print(f'\\n[{it}] Validation:')\n",
    "        for l in D.names:\n",
    "            X[l] = X[l].to(device)\n",
    "            print('\\n', l, ' --> ', other[l])\n",
    "            print('<< ', D.ind2sent(X[l][0].cpu(), l))\n",
    "            print('== ', D.ind2sent(X[other[l]][0].cpu(), other[l]))\n",
    "            encoder_outputs, decoder_outputs =\\\n",
    "                       wr.encode_decode(X[l], \n",
    "                                        l,\n",
    "                                        other[l],\n",
    "                                        X[other[l]].shape[1])\n",
    "            _, ind = decoder_outputs[0].cpu().topk(1, dim=1)\n",
    "            print('>> ', D.ind2sent(ind, other[l]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начало обучения не предвещает ничего хорошего:\n",
    " \n",
    "```\n",
    "Iterations: 0\n",
    "Saved model to: checkpoint.0\n",
    "Last loss:\n",
    "  d_loss = tensor(2.7549, device='cuda:0')\n",
    "  tr_loss = tensor(40.1062, device='cuda:0')\n",
    "[0] Validation:\n",
    "\n",
    " fr  -->  en\n",
    "<<  une statue argentee d apos hommes sur des velos .\n",
    "==  a silver statue of men on bikes .\n",
    ">>  chelsea chelsea chelsea chelsea chelsea chelsea chelsea chelsea chelsea\n",
    "\n",
    " en  -->  fr\n",
    "<<  a silver statue of men on bikes .\n",
    "==  une statue argentee d apos hommes sur des velos .\n",
    ">>  danseur danseur danseur danseur danseur danseur danseur danseur danseur danseur danseur\n",
    "Iterations: 10\n",
    "Iterations: 20\n",
    "Iterations: 30\n",
    "Iterations: 40\n",
    "Iterations: 50\n",
    "Iterations: 60\n",
    "Iterations: 70\n",
    "Iterations: 80\n",
    "Iterations: 90\n",
    "Iterations: 100\n",
    "Saved model to: checkpoint.100\n",
    "Last loss:\n",
    "  d_loss = tensor(2.9585, device='cuda:0')\n",
    "  tr_loss = tensor(34.4259, device='cuda:0')\n",
    "[100] Validation:\n",
    "\n",
    " fr  -->  en\n",
    "<<  le chien chasse la chevre dans la cour .\n",
    "==  the dog is chasing the goat around the yard .\n",
    ">>  a a a a a a a a a a a\n",
    "\n",
    " en  -->  fr\n",
    "<<  the dog is chasing the goat around the yard .\n",
    "==  le chien chasse la chevre dans la cour .\n",
    ">>  plage plage plage plage plage plage plage plage plage plage\n",
    "Iterations: 110\n",
    "Iterations: 120\n",
    "Iterations: 130\n",
    "Iterations: 140\n",
    "Iterations: 150\n",
    "Iterations: 160\n",
    "Iterations: 170\n",
    "Iterations: 180\n",
    "Iterations: 190\n",
    "Iterations: 200\n",
    "Saved model to: checkpoint.200\n",
    "Last loss:\n",
    "  d_loss = tensor(2.7812, device='cuda:0')\n",
    "  tr_loss = tensor(26.7634, device='cuda:0')\n",
    "[200] Validation:\n",
    "\n",
    " fr  -->  en\n",
    "<<  un jeune homme tenant une enorme tronconneuse .\n",
    "==  a young man holding a huge chainsaw .\n",
    ">>  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
    "\n",
    " en  -->  fr\n",
    "<<  a young man holding a huge chainsaw .\n",
    "==  un jeune homme tenant une enorme tronconneuse .\n",
    ">>  sur sur sur sur sur sur sur sur sur\n",
    "Iterations: 210\n",
    "Iterations: 220\n",
    "Iterations: 230\n",
    "Iterations: 240\n",
    "Iterations: 250\n",
    "Iterations: 260\n",
    "Iterations: 270\n",
    "Iterations: 280\n",
    "Iterations: 290\n",
    "Iterations: 300\n",
    "Saved model to: checkpoint.300\n",
    "Last loss:\n",
    "  d_loss = tensor(2.7569, device='cuda:0')\n",
    "  tr_loss = tensor(24.1434, device='cuda:0')\n",
    "[300] Validation:\n",
    "\n",
    " fr  -->  en\n",
    "<<  une foule se rassemble pour ecouter un orchestre\n",
    "==  crowd gathers to listen to a band\n",
    ">>  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
    "\n",
    " en  -->  fr\n",
    "<<  crowd gathers to listen to a band\n",
    "==  une foule se rassemble pour ecouter un orchestre\n",
    ">>  une une une une une une une une une\n",
    "Iterations: 310\n",
    "Iterations: 320\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "525px",
    "left": "825px",
    "right": "67px",
    "top": "72px",
    "width": "474px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
